{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Object detection with Tensorflow object detection API"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwXGi8kjjZH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core GPU runtime deps TensorFlow 2.15 needs\n",
        "!apt-get update -y\n",
        "!apt-get install -y --no-install-recommends \\\n",
        "    cuda-command-line-tools-12-2 \\\n",
        "    cuda-cupti-12-2 \\\n",
        "    libcudnn8=8.9.4.25-1+cuda12.2 \\\n",
        "    libcudnn8-dev=8.9.4.25-1+cuda12.2 \\\n",
        "    libcusparse-dev-12-2\n",
        "\n",
        "# Clean remnants\n",
        "!rm -rf /content/sample_data\n"
      ],
      "metadata": {
        "id": "Q1LYbNUeRn0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU (you should see NVIDIA L4 or similar)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "XLXMSB7Q8PFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 tf-slim protobuf==3.20.*"
      ],
      "metadata": {
        "id": "Xhtz3OQDk7CF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Clone the models repo\n",
        "%cd /content\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research\n"
      ],
      "metadata": {
        "id": "2R126SkCmnlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compile protobufs\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "N-XIRnNym5mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Install the Object Detection API properly\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "id": "mdSP_pIXm-vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15.0 keras==2.15.0 tf-slim protobuf==3.20.*"
      ],
      "metadata": {
        "id": "frQ9RA3loh9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"ðŸ§  TF version:\", tf.__version__)\n",
        "print(\"âœ… GPU:\", tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "LU3WMlSsD5dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "from object_detection.utils import label_map_util, config_util\n",
        "from object_detection import model_lib_v2\n",
        "\n",
        "print(\"âœ… TensorFlow version:\", tf.__version__)\n",
        "print(\"âœ… GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"âœ… Object Detection API loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "OPbwe2oegAdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/tfexample_decoder.py /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "waLAce_NDX0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 20 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "tOvo97JWDjxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove broken estimator import\n",
        "!sed -i '/from tensorflow.compat.v1 import estimator as tf_estimator/d' object_detection/inputs.py\n",
        "!sed -i '/import tensorflow_estimator as tf_estimator/d' object_detection/inputs.py\n"
      ],
      "metadata": {
        "id": "wgxN_pSAf8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AaQP2LkupuP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-J7whqrkIl"
      },
      "source": [
        "You'll start by installing the Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi28cqGGFWnY"
      },
      "outputs": [],
      "source": [
        "# uncomment the next line if you want to delete an existing models directory\n",
        "!rm -rf ./models/\n",
        "\n",
        "# clone the Tensorflow Model Garden\n",
        "!git clone --depth 1 https://github.com/tensorflow/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwdsBdGhFanc"
      },
      "outputs": [],
      "source": [
        "# For compatibility. Pin tf-models-official version so it will use Tensorflow 2.15.\n",
        "!sed -i 's/tf-models-official>=2.5.1/tf-models-official==2.15.0/g' ./models/research/object_detection/packages/tf2/setup.py\n",
        "\n",
        "# Compile the Object Detection API protocol buffers and install the necessary packages\n",
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbgcg4PpmrAB"
      },
      "outputs": [],
      "source": [
        "# Downgrade protobuf for compatibility. You can ignore dependency conflicts in the output.\n",
        "!pip install protobuf==3.20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0PEuhylmrAB"
      },
      "source": [
        "**IMPORTANT**: Please restart the runtime for the changes to take effect. You can either click the `Restart Runtime` button in the output of the cell above, or go to `Runtime > Restart Session` on the Menu bar above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/tf-models-official>=2.5.1/tf-models-official==2.15.0/g' ./models/research/object_detection/packages/tf2/setup.py\n"
      ],
      "metadata": {
        "id": "ZG3z5SOxmPTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd models/research/ && protoc object_detection/protos/*.proto --python_out=.\n",
        "!cp models/research/object_detection/packages/tf2/setup.py models/research/\n",
        "!pip install ./models/research/\n"
      ],
      "metadata": {
        "id": "hExuEVOymmq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20"
      ],
      "metadata": {
        "id": "kIOVpkX-muvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Let's now import the packages you will use in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")"
      ],
      "metadata": {
        "id": "TzJkZvUbsNUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util, label_map_util"
      ],
      "metadata": {
        "id": "CE3L-qy5uMIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roboflow data"
      ],
      "metadata": {
        "id": "I_E82REisoz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and set up Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"3zX0IiVPf7UfB1zBmrKv\")"
      ],
      "metadata": {
        "id": "6CI8oOwIsroT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "workspace = rf.workspace(\"ssdcctv\")\n",
        "project = workspace.project(\"my-first-project-nwbay\")\n",
        "dataset = project.version(1).download(\"tfrecord\")"
      ],
      "metadata": {
        "id": "OOT0k48Dsxkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths\n",
        "dataset_location = dataset.location\n",
        "train_data_path = os.path.join(dataset_location, \"train\", \"objects.tfrecord\")\n",
        "val_data_path = os.path.join(dataset_location, \"valid\", \"objects.tfrecord\")\n",
        "label_map_path = os.path.join(dataset_location, \"train\", \"objects_label_map.pbtxt\")\n",
        "test_data_path = os.path.join(dataset_location, \"test\", \"objects.tfrecord\")"
      ],
      "metadata": {
        "id": "xqKTkmfes2TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load label map\n",
        "categories = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n",
        "num_classes = len(categories)"
      ],
      "metadata": {
        "id": "oe-FxUC3uE7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pipeline configuration"
      ],
      "metadata": {
        "id": "-Z-8fAoow3CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "    },\n",
        "    'ssd-mobilenet-v2-fpnlite-320': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'ssd_resnet50_v1': {\n",
        "        'model_name': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n",
        "    }\n",
        "}\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ],
      "metadata": {
        "id": "eqX7w9bXxAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "IRB4ox0i__JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "\n",
        "if chosen_model == 'efficientdet-d0':\n",
        "  batch_size = 4\n",
        "else:\n",
        "  batch_size = 16"
      ],
      "metadata": {
        "id": "qULIk-IlEb9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set file locations\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'"
      ],
      "metadata": {
        "id": "Qa3nIh0-4wFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_data_path), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_data_path), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_path), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "VMQ0Fzn3C8si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ],
      "metadata": {
        "id": "us7CvsUkEl2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "metadata": {
        "id": "HPR_tTUJGLQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "x3YcCNMgIDt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '2,3d' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "itCUL_Ycfjp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '/from __future__ import absolute_import/a import tensorflow as tf' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "1Qo5kpKLU49H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '1,/^$/d' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "9ZVs1m71jzOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '1i # coding=utf-8\\n# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\\n#\\n# Licensed under the Apache License, Version 2.0 (the \"License\");\\n# you may not use this file except in compliance with the License.\\n# You may obtain a copy of the License at\\n#\\n#     http://www.apache.org/licenses/LICENSE-2.0\\n\\nfrom __future__ import absolute_import\\nimport tensorflow as tf\\n' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "otK2sQ3Bj4iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py https://raw.githubusercontent.com/tensorflow/models/master/research/slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "-jPgECtFnNqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i '/from __future__ import absolute_import/a import tensorflow as tf' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "lWT2_7ZRnR3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 15 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "pMZPWFIgnUp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim --force-reinstall\n"
      ],
      "metadata": {
        "id": "WrcKAqbbpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add `import tensorflow as tf` after the `__future__` line\n",
        "!sed -i '/from __future__ import absolute_import/a import tensorflow as tf' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "vYDAp4pZpmd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "lFtOOkMIqFPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_header = \"\"\"# coding=utf-8\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\\\"\\\"\\\"Contains the TFExampleDecoder its associated helper classes.\n",
        "\n",
        "The TFExampleDecode is a DataDecoder used to decode TensorFlow Example protos.\n",
        "In order to do so each requested item must be paired with one or more Example\n",
        "features that are parsed to produce the Tensor-based manifestation of the item.\n",
        "\\\"\\\"\\\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "\"\"\"\n",
        "\n",
        "path = \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\"\n",
        "with open(path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Replace first ~30 lines with the clean header\n",
        "lines = fixed_header.splitlines(keepends=True) + lines[30:]\n",
        "\n",
        "# Write it back\n",
        "with open(path, \"w\") as f:\n",
        "    f.writelines(lines)\n",
        "\n",
        "# Preview to confirm\n",
        "!head -n 20 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "q7cIMr-Yqw7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the broken file\n",
        "path = \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\"\n",
        "\n",
        "# Read the file\n",
        "with open(path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# If 'import six' is not already in there, add it after the other imports\n",
        "if not any(\"import six\" in line for line in lines):\n",
        "    insert_index = next(i for i, line in enumerate(lines) if line.strip().startswith(\"import tensorflow\"))\n",
        "    lines.insert(insert_index + 1, \"import six\\n\")\n",
        "\n",
        "# Write it back\n",
        "with open(path, \"w\") as f:\n",
        "    f.writelines(lines)\n",
        "\n",
        "# Confirm it's there\n",
        "!head -n 30 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "7XFnLPK8rUKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\"\n",
        "\n",
        "# Read the file\n",
        "with open(path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Add 'import abc' if not already there\n",
        "if not any(\"import abc\" in line for line in lines):\n",
        "    insert_index = next(i for i, line in enumerate(lines) if line.strip().startswith(\"import tensorflow\"))\n",
        "    lines.insert(insert_index + 1, \"import abc\\n\")\n",
        "\n",
        "# Save the updated file\n",
        "with open(path, \"w\") as f:\n",
        "    f.writelines(lines)\n",
        "\n",
        "# Confirm visually\n",
        "!head -n 30 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "68NMWpCZrzu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/control_flow_ops.case/tf.case/g' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "LRWlhvJHxf7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/control_flow_ops\\.cond/tf.cond/g' /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "zyQjaVPy3G7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py') as f:\n",
        "    for i, line in enumerate(f.readlines()[:455]):\n",
        "        print(f\"{i+1:>2}: {line.rstrip()}\")\n"
      ],
      "metadata": {
        "id": "SrM1v1-PaJsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import sys\n",
        "import tensorflow.python.ops.control_flow_ops as cf_ops\n",
        "\n",
        "# Ensure that 'case' is available in control_flow_ops\n",
        "if not hasattr(cf_ops, \"case\"):\n",
        "    cf_ops.case = tf.case\n",
        "\n",
        "# (Optional) Confirm the patch worked:\n",
        "print(\"control_flow_ops.case patched to:\", cf_ops.case)\n"
      ],
      "metadata": {
        "id": "HUYmHwwfLMaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "#import sys\n",
        "\n",
        "#import tensorflow.python.ops.control_flow_ops as cf_ops\n",
        "# Patch the module in sys.modules so that any future imports also see the change.\n",
        "sys.modules[\"tensorflow.python.ops.control_flow_ops\"].case = tf.case\n",
        "\n",
        "# Verify the patch:\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "print(\"Patched control_flow_ops.case:\", control_flow_ops.case)\n"
      ],
      "metadata": {
        "id": "SFURfqOqNGw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tf_slim\n",
        "import os\n",
        "\n",
        "# Path to the tfexample_decoder.py file inside tf_slim\n",
        "slim_decoder_path = os.path.join(tf_slim.__path__[0], 'data', 'tfexample_decoder.py')\n",
        "\n",
        "# Read the file\n",
        "with open(slim_decoder_path, 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Replace the broken control_flow_ops.case with tf.case\n",
        "content = content.replace('control_flow_ops.case', 'tf.case')\n",
        "\n",
        "# Patch it\n",
        "with open(slim_decoder_path, 'w') as file:\n",
        "    file.write(content)\n",
        "\n",
        "print(\"âœ… Patched tf_slim to use tf.case instead of control_flow_ops.case.\")\n"
      ],
      "metadata": {
        "id": "pFeh_Rd4QKsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "gCSbv4SHJVAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "metadata": {
        "id": "PhrxZXl9N9nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "3HDz8MZ6JLT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "Yntb5KDfH-uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "metadata": {
        "id": "AVIKxovcIGvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "  --model_dir=\"/content/training/\" \\\n",
        "  --alsologtostderr \\\n",
        "  --num_train_steps=40000 \\\n",
        "  --sample_1_of_n_eval_examples=1\n"
      ],
      "metadata": {
        "id": "AMg4NiMDIyCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export model inference graph"
      ],
      "metadata": {
        "id": "piLZ061sQ-tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Export the model ===\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "    --trained_checkpoint_dir=\"/content/training\" \\\n",
        "    --output_directory=\"/content/models/my_model/exported_model\"\n"
      ],
      "metadata": {
        "id": "1m5KJiJbQJNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the exported model\n",
        "export_dir = '/content/models/my_model/exported_model'\n",
        "zip_path = '/content/models/my_model/model_SSD_Mobilenetv2_40000_T4.zip'\n",
        "\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', export_dir)\n"
      ],
      "metadata": {
        "id": "3cGcU1BcLoWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the .zip file\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "FqVq9J8IStKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Trained model with test image"
      ],
      "metadata": {
        "id": "Jb6x-DhNclaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import six\n",
        "import time\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "metadata": {
        "id": "ZbFGB0cCclAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "N9RXie76rcbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the exported SavedModel\n",
        "model_dir = \"/content/models/my_model/exported_model/saved_model\"\n",
        "detect_fn = tf.saved_model.load(model_dir)"
      ],
      "metadata": {
        "id": "2-ky6nQgmWnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#not used?\n",
        "def load_image_into_numpy_array(path):\n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
        "    return np.array(image)\n"
      ],
      "metadata": {
        "id": "_l9BiWGrfYHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OxWU7K_oyVwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#not used?\n",
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  return output_dict"
      ],
      "outputs": [],
      "metadata": {
        "id": "kxAf3XJBzLHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper to load and display image with predictions\n",
        "def show_inference(model, image_path):\n",
        "    image_np = image_tensor.numpy() if tf.is_tensor(image_tensor) else image_tensor\n",
        "    output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=10,\n",
        "        min_score_thresh=0.3,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.imshow(image_np)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fLcUOHaRmpvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on test images\n",
        "test_images_folder = os.path.join(dataset_location, \"test\")\n",
        "image_files = [os.path.join(test_images_folder, f) for f in os.listdir(test_images_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]"
      ],
      "metadata": {
        "id": "ceN3iQWCmw-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show predictions for a few test images\n",
        "for image_path in image_files[:5]:\n",
        "    print(f\"Running inference on: {image_path}\")\n",
        "    show_inference(detect_fn, image_path)"
      ],
      "metadata": {
        "id": "Ps1OTgjLm1LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(example):\n",
        "    features = {\n",
        "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example, features)"
      ],
      "metadata": {
        "id": "wDThNCG1sE2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "def run_model_on_roboflow_tfrecord(tfrecord_path, model, num_images=5):\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(parse_tfrecord)\n",
        "\n",
        "    for i, record in enumerate(dataset.take(num_images)):\n",
        "        image_bytes = record['image/encoded'].numpy()\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # Run inference\n",
        "        output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "        # Visualization\n",
        "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np,\n",
        "            output_dict['detection_boxes'],\n",
        "            output_dict['detection_classes'],\n",
        "            output_dict['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=10,\n",
        "            min_score_thresh=0.3,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(image_np)\n",
        "        plt.axis('off')\n",
        "        plt.title(record['image/filename'].numpy().decode('utf-8'))\n",
        "        plt.show()\n",
        "\n",
        "# Run it on test TFRecord\n",
        "run_model_on_roboflow_tfrecord(test_data_path, detect_fn, num_images=5)\n"
      ],
      "metadata": {
        "id": "ryt7CZzKr7cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_and_show(image_path):\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # Process results\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {k: v[0, :num_detections].numpy()\n",
        "                  for k, v in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    # Visualize results\n",
        "    image_with_detections = image_np.copy()\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=20,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_with_detections)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1bUeQMdKAuK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Set TFRecord and output path\n",
        "tfrecord_path = '/content/My-First-Project-1/test/objects.tfrecord'\n",
        "output_dir = '/content/extracted_test_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the TFRecord schema\n",
        "def parse_tfrecord2(example):\n",
        "    features = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example, features)\n",
        "\n",
        "# Read and extract images\n",
        "raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "parsed_dataset = raw_dataset.map(parse_tfrecord2)\n",
        "\n",
        "for i, parsed_record in enumerate(parsed_dataset):\n",
        "    img_bytes = parsed_record['image/encoded'].numpy()\n",
        "    filename = parsed_record['image/filename'].numpy().decode('utf-8')\n",
        "    image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "    image.save(os.path.join(output_dir, filename))\n",
        "\n",
        "    if i >= 10:  # Save only 5 images for now\n",
        "        break\n",
        "\n",
        "print(\"âœ… Saved extracted images to:\", output_dir)\n"
      ],
      "metadata": {
        "id": "RRH2VdI5AD3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with one of the extracted images\n",
        "image_path = '/content/extracted_test_images/25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.0204a33669487196240645aa25d180e6.jpg'\n",
        "run_inference_and_show(image_path)\n"
      ],
      "metadata": {
        "id": "ArMYop7ZAhKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "# Output folder\n",
        "output_dir = \"/content/extracted_test_images\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def run_model_on_roboflow_tfrecord(tfrecord_path, model, num_images=10):\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(parse_tfrecord)\n",
        "\n",
        "    for i, record in enumerate(dataset.take(num_images)):\n",
        "        image_bytes = record['image/encoded'].numpy()\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # Run inference\n",
        "        input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "        detections = model(input_tensor)\n",
        "\n",
        "        # Process results\n",
        "        num_detections = int(detections.pop('num_detections'))\n",
        "        detections = {k: v[0, :num_detections].numpy()\n",
        "                      for k, v in detections.items()}\n",
        "        detections['num_detections'] = num_detections\n",
        "        detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "        # Visualization\n",
        "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes'],\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=10,\n",
        "            min_score_thresh=0.3,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "        # Save image with detections\n",
        "        filename = record['image/filename'].numpy().decode('utf-8')\n",
        "        save_path = os.path.join(output_dir, f\"{i+1}_{filename}\")\n",
        "        Image.fromarray(image_np).save(save_path)\n",
        "        print(f\"âœ… Saved: {save_path}\")\n",
        "\n",
        "        # Optional: Show the image\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(image_np)\n",
        "        plt.axis('off')\n",
        "        plt.title(filename)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "RtAddEaWKQkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip it\n",
        "zip_path = \"/content/tested_image_SSD_mobilenetv2.zip\"\n",
        "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', output_dir)\n"
      ],
      "metadata": {
        "id": "QNt1prRXDa85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(zip_path)"
      ],
      "metadata": {
        "id": "_riwg8QLDcw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation MAP"
      ],
      "metadata": {
        "id": "BKkvA0iXEDBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "  --model_dir=\"/content/training/\" \\\n",
        "  --checkpoint_dir=\"/content/training/\" \\\n",
        "  --run_once=True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "owoAJ2J7EGjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tfexample_decoder.py"
      ],
      "metadata": {
        "id": "pOlbA3vaKnIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "src = \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\"\n",
        "dst = \"/content/tfexample_decoder.py\"\n",
        "\n",
        "shutil.copy(src, dst)\n",
        "print(\"Copied to\", dst)\n"
      ],
      "metadata": {
        "id": "LjtxSeEsKwQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip tfexample_decoder.zip /content/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "hJkbYFeOK-v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/tfexample_decoder.zip\")\n"
      ],
      "metadata": {
        "id": "a_HplyBTLCwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Jb6x-DhNclaj"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}