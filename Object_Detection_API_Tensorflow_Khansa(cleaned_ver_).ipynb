{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# Object detection with Tensorflow object detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setting GPU"
      ],
      "metadata": {
        "id": "oAbBIrW08MPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ONLY IF YOU HAVE SOME MANY RESTART SESSION\n",
        "%reset -f\n",
        "import os\n",
        "os.kill(os.getpid(), 9)\n"
      ],
      "metadata": {
        "id": "cT6d4W4ZQFE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core GPU runtime deps TensorFlow 2.15 needs\n",
        "!apt-get update -y\n",
        "!apt-get install -y --no-install-recommends \\\n",
        "    cuda-command-line-tools-12-2 \\\n",
        "    cuda-cupti-12-2 \\\n",
        "    libcudnn8=8.9.4.25-1+cuda12.2 \\\n",
        "    libcudnn8-dev=8.9.4.25-1+cuda12.2 \\\n",
        "    libcusparse-dev-12-2\n",
        "\n",
        "# Clean remnants\n",
        "!rm -rf /content/sample_data\n"
      ],
      "metadata": {
        "id": "Q1LYbNUeRn0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU (you should see NVIDIA L4 or similar)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "XLXMSB7Q8PFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR-J7whqrkIl"
      },
      "source": [
        "You'll start by installing the Tensorflow 2 [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. TensorFlow 2.15 + matching Keras + tf-slim + Protobuf\n",
        "!pip install --upgrade pip\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 tf-slim protobuf==3.20.*"
      ],
      "metadata": {
        "id": "N08brs-Sq3j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0PEuhylmrAB"
      },
      "source": [
        "**IMPORTANT**: Please restart the runtime for the changes to take effect. You can either click the `Restart Runtime` button in the output of the cell above, or go to `Runtime > Restart Session` on the Menu bar above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Clone the models repo\n",
        "%cd /content\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research"
      ],
      "metadata": {
        "id": "tS4MwNMXB2yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compile protobufs\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "sW1URnXjB8QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Install the Object Detection API properly\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "id": "Ft0sB7BvB-gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yes install again then restart again\n",
        "!pip install tensorflow==2.15.0 keras==2.15.0 tf-slim protobuf==3.20.*"
      ],
      "metadata": {
        "id": "IlOUcB_qCCxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**: Please restart the runtime for the changes to take effect. You can either click the `Restart Runtime` button in the output of the cell above, or go to `Runtime > Restart Session` on the Menu bar above."
      ],
      "metadata": {
        "id": "4INYBKl6CKyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/tfexample_decoder.py /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "waLAce_NDX0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 20 /usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\n"
      ],
      "metadata": {
        "id": "tOvo97JWDjxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove broken estimator import\n",
        "!sed -i '/from tensorflow.compat.v1 import estimator as tf_estimator/d' object_detection/inputs.py\n",
        "!sed -i '/import tensorflow_estimator as tf_estimator/d' object_detection/inputs.py\n"
      ],
      "metadata": {
        "id": "wgxN_pSAf8Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21tUtyyVrkIt"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Let's now import the packages you will use in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(\"ðŸ§  Python version:\", sys.version)\n"
      ],
      "metadata": {
        "id": "J6OghUd0kSHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util, config_util\n",
        "from object_detection import model_lib_v2\n",
        "\n",
        "print(\"âœ… TensorFlow version:\", tf.__version__)\n",
        "print(\"âœ… GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"âœ… Object Detection API loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "OPbwe2oegAdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZcqD4NLdnf4"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import zipfile\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "\n",
        "import glob\n",
        "import imageio\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Roboflow data"
      ],
      "metadata": {
        "id": "I_E82REisoz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install and set up Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"3zX0IiVPf7UfB1zBmrKv\")"
      ],
      "metadata": {
        "id": "6CI8oOwIsroT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "workspace = rf.workspace(\"ssdcctv\")\n",
        "project = workspace.project(\"my-first-project-nwbay\")\n",
        "dataset = project.version(1).download(\"tfrecord\")"
      ],
      "metadata": {
        "id": "OOT0k48Dsxkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths\n",
        "dataset_location = dataset.location\n",
        "train_data_path = os.path.join(dataset_location, \"train\", \"objects.tfrecord\")\n",
        "val_data_path = os.path.join(dataset_location, \"valid\", \"objects.tfrecord\")\n",
        "label_map_path = os.path.join(dataset_location, \"train\", \"objects_label_map.pbtxt\")\n",
        "test_data_path = os.path.join(dataset_location, \"test\", \"objects.tfrecord\")"
      ],
      "metadata": {
        "id": "xqKTkmfes2TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load label map\n",
        "categories = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n",
        "num_classes = len(categories)"
      ],
      "metadata": {
        "id": "oe-FxUC3uE7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pipeline configuration"
      ],
      "metadata": {
        "id": "-Z-8fAoow3CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the chosen_model variable to deploy different models available in the TF2 object detection zoo\n",
        "chosen_model = 'efficientdet-d0'\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'efficientdet-d0': {\n",
        "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
        "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
        "    },\n",
        "    'ssd-mobilenet-v2-fpnlite-320': {\n",
        "        'model_name': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "    'ssd_resnet50_v1': {\n",
        "        'model_name': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz',\n",
        "    }\n",
        "}\n",
        "\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']"
      ],
      "metadata": {
        "id": "eqX7w9bXxAde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"mymodel\" folder for holding pre-trained weights and configuration files\n",
        "%mkdir /content/models/mymodel/\n",
        "%cd /content/models/mymodel/\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
        "!wget {download_config}"
      ],
      "metadata": {
        "id": "IRB4ox0i__JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "\n",
        "if chosen_model == 'efficientdet-d0':\n",
        "  batch_size = 4\n",
        "else:\n",
        "  batch_size = 16"
      ],
      "metadata": {
        "id": "qULIk-IlEb9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set file locations\n",
        "pipeline_fname = '/content/models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = '/content/models/mymodel/' + model_name + '/checkpoint/ckpt-0'"
      ],
      "metadata": {
        "id": "Qa3nIh0-4wFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "%cd /content/models/mymodel\n",
        "print('writing custom configuration file')\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_data_path), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_data_path), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_path), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate (because it's too high in the default config file)\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .08', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .026666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "VMQ0Fzn3C8si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) Display the custom configuration file's contents\n",
        "!cat /content/models/mymodel/pipeline_file.config"
      ],
      "metadata": {
        "id": "us7CvsUkEl2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = '/content/models/mymodel/pipeline_file.config'\n",
        "model_dir = '/content/training/'"
      ],
      "metadata": {
        "id": "HPR_tTUJGLQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "x3YcCNMgIDt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir '/content/training/train'\n"
      ],
      "metadata": {
        "id": "DiauwKTadB9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "  --model_dir=\"/content/training/\" \\\n",
        "  --alsologtostderr \\\n",
        "  --num_train_steps=40000 \\\n",
        "  --sample_1_of_n_eval_examples=1\n"
      ],
      "metadata": {
        "id": "AMg4NiMDIyCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export model inference graph"
      ],
      "metadata": {
        "id": "piLZ061sQ-tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# === Export the model ===\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "    --trained_checkpoint_dir=\"/content/training\" \\\n",
        "    --output_directory=\"/content/models/my_model/exported_model\"\n"
      ],
      "metadata": {
        "id": "1m5KJiJbQJNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the exported model\n",
        "export_dir = '/content/models/my_model/exported_model'\n",
        "zip_path = '/content/models/my_model/exported_model.zip'\n",
        "\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', export_dir)\n"
      ],
      "metadata": {
        "id": "3cGcU1BcLoWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the .zip file\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "FqVq9J8IStKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Trained model with test image"
      ],
      "metadata": {
        "id": "Jb6x-DhNclaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import six\n",
        "import time\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "metadata": {
        "id": "ZbFGB0cCclAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "N9RXie76rcbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the exported SavedModel\n",
        "model_dir = \"/content/models/my_model/exported_model/saved_model\"\n",
        "detect_fn = tf.saved_model.load(model_dir)"
      ],
      "metadata": {
        "id": "2-ky6nQgmWnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#not used?\n",
        "def load_image_into_numpy_array(path):\n",
        "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(img_data)).convert(\"RGB\")\n",
        "    return np.array(image)\n"
      ],
      "metadata": {
        "id": "_l9BiWGrfYHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "OxWU7K_oyVwq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#not used?\n",
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  return output_dict"
      ],
      "outputs": [],
      "metadata": {
        "id": "kxAf3XJBzLHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper to load and display image with predictions\n",
        "def show_inference(model, image_path):\n",
        "    image_np = image_tensor.numpy() if tf.is_tensor(image_tensor) else image_tensor\n",
        "    output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=10,\n",
        "        min_score_thresh=0.3,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.imshow(image_np)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "fLcUOHaRmpvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference on test images\n",
        "test_images_folder = os.path.join(dataset_location, \"test\")\n",
        "image_files = [os.path.join(test_images_folder, f) for f in os.listdir(test_images_folder) if f.endswith(\".jpg\") or f.endswith(\".png\")]"
      ],
      "metadata": {
        "id": "ceN3iQWCmw-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show predictions for a few test images\n",
        "for image_path in image_files[:5]:\n",
        "    print(f\"Running inference on: {image_path}\")\n",
        "    show_inference(detect_fn, image_path)"
      ],
      "metadata": {
        "id": "Ps1OTgjLm1LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(example):\n",
        "    features = {\n",
        "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/bbox/xmin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/xmax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymin': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/bbox/ymax': tf.io.VarLenFeature(tf.float32),\n",
        "        'image/object/class/text': tf.io.VarLenFeature(tf.string),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example, features)"
      ],
      "metadata": {
        "id": "wDThNCG1sE2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "def run_model_on_roboflow_tfrecord(tfrecord_path, model, num_images=5):\n",
        "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    dataset = dataset.map(parse_tfrecord)\n",
        "\n",
        "    for i, record in enumerate(dataset.take(num_images)):\n",
        "        image_bytes = record['image/encoded'].numpy()\n",
        "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
        "        image_np = np.array(image)\n",
        "\n",
        "        # Run inference\n",
        "        output_dict = run_inference_for_single_image(model, image_np)\n",
        "\n",
        "        # Visualization\n",
        "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np,\n",
        "            output_dict['detection_boxes'],\n",
        "            output_dict['detection_classes'],\n",
        "            output_dict['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=10,\n",
        "            min_score_thresh=0.3,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(image_np)\n",
        "        plt.axis('off')\n",
        "        plt.title(record['image/filename'].numpy().decode('utf-8'))\n",
        "        plt.show()\n",
        "\n",
        "# Run it on test TFRecord\n",
        "run_model_on_roboflow_tfrecord(test_data_path, detect_fn, num_images=5)\n"
      ],
      "metadata": {
        "id": "ryt7CZzKr7cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference_and_show(image_path):\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "    input_tensor = tf.convert_to_tensor(image_np)[tf.newaxis, ...]\n",
        "\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # Process results\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {k: v[0, :num_detections].numpy()\n",
        "                  for k, v in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    # Visualize results\n",
        "    image_with_detections = image_np.copy()\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=20,\n",
        "        min_score_thresh=0.4,\n",
        "        agnostic_mode=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_with_detections)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1bUeQMdKAuK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Set TFRecord and output path\n",
        "tfrecord_path = '/content/My-First-Project-1/test/objects.tfrecord'\n",
        "output_dir = '/content/extracted_test_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Define the TFRecord schema\n",
        "def parse_tfrecord2(example):\n",
        "    features = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example, features)\n",
        "\n",
        "# Read and extract images\n",
        "raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "parsed_dataset = raw_dataset.map(parse_tfrecord2)\n",
        "\n",
        "for i, parsed_record in enumerate(parsed_dataset):\n",
        "    img_bytes = parsed_record['image/encoded'].numpy()\n",
        "    filename = parsed_record['image/filename'].numpy().decode('utf-8')\n",
        "    image = Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")\n",
        "    image.save(os.path.join(output_dir, filename))\n",
        "\n",
        "    if i >= 10:  # Save only 5 images for now\n",
        "        break\n",
        "\n",
        "print(\"âœ… Saved extracted images to:\", output_dir)\n"
      ],
      "metadata": {
        "id": "RRH2VdI5AD3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with one of the extracted images\n",
        "image_path = '/content/extracted_test_images/25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.0204a33669487196240645aa25d180e6.jpg'\n",
        "run_inference_and_show(image_path)\n"
      ],
      "metadata": {
        "id": "ArMYop7ZAhKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/extracted_test_images', 'zip', '/content/extracted_test_images')\n"
      ],
      "metadata": {
        "id": "QNt1prRXDa85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/extracted_test_images.zip')\n"
      ],
      "metadata": {
        "id": "_riwg8QLDcw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation MAP"
      ],
      "metadata": {
        "id": "BKkvA0iXEDBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "  --pipeline_config_path=\"/content/models/mymodel/pipeline_file.config\" \\\n",
        "  --model_dir=\"/content/training/\" \\\n",
        "  --checkpoint_dir=\"/content/training/\" \\\n",
        "  --run_once=True\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "owoAJ2J7EGjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Jb6x-DhNclaj"
      ],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}